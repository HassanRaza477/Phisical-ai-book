<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-chapters/part2/chapter7" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 7: Vision-Language-Action (VLA) Models | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://HassanRaza477.github.io/Phisical-ai-book/docs/chapters/part2/chapter7"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 7: Vision-Language-Action (VLA) Models | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Our robot can now see. But sight without understanding is just data. To build a truly intelligent agent, that sight must be connected to language and, most importantly, to action. This chapter introduces a concept from the absolute cutting edge of AI research: Vision-Language-Action (VLA) models."><meta data-rh="true" property="og:description" content="Our robot can now see. But sight without understanding is just data. To build a truly intelligent agent, that sight must be connected to language and, most importantly, to action. This chapter introduces a concept from the absolute cutting edge of AI research: Vision-Language-Action (VLA) models."><link data-rh="true" rel="icon" href="/Phisical-ai-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://HassanRaza477.github.io/Phisical-ai-book/docs/chapters/part2/chapter7"><link data-rh="true" rel="alternate" href="https://HassanRaza477.github.io/Phisical-ai-book/docs/chapters/part2/chapter7" hreflang="en"><link data-rh="true" rel="alternate" href="https://HassanRaza477.github.io/Phisical-ai-book/docs/chapters/part2/chapter7" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 7: Vision-Language-Action (VLA) Models","item":"https://HassanRaza477.github.io/Phisical-ai-book/docs/chapters/part2/chapter7"}]}</script><link rel="alternate" type="application/rss+xml" href="/Phisical-ai-book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Phisical-ai-book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/Phisical-ai-book/assets/css/styles.84a46baa.css">
<script src="/Phisical-ai-book/assets/js/runtime~main.523edc33.js" defer="defer"></script>
<script src="/Phisical-ai-book/assets/js/main.dcb800d9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Phisical-ai-book/img/logo-footer.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top navbar--dark"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Phisical-ai-book/"><b class="navbar__title text--truncate">ðŸ¤– Humanoid Robotics</b></a><a class="navbar__item navbar__link navbar-book-btn" href="/Phisical-ai-book/docs/intro">ðŸ“š Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/yourrepo" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar-github-btn">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a class="navbar__item navbar__link navbar-login-btn" href="/Phisical-ai-book/login">Login</a><a class="navbar__item navbar__link navbar-signup-btn" href="/Phisical-ai-book/signup">Sign Up</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS darkNavbarColorModeToggle_X3D1" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Phisical-ai-book/docs/intro"><span title="Introduction to the Physical AI &amp; Humanoid Robotics Book" class="linkLabel_WmDU">Introduction to the Physical AI &amp; Humanoid Robotics Book</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Phisical-ai-book/docs/chapters/part1/chapter1"><span title="chapters" class="categoryLinkLabel_W154">chapters</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Phisical-ai-book/docs/chapters/part1/chapter1"><span title="part1" class="categoryLinkLabel_W154">part1</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Phisical-ai-book/docs/chapters/part2/chapter5"><span title="part2" class="categoryLinkLabel_W154">part2</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Phisical-ai-book/docs/chapters/part2/chapter5"><span title="Chapter 5: NVIDIA Isaac Sim: From Simulation to Synthetic Data" class="linkLabel_WmDU">Chapter 5: NVIDIA Isaac Sim: From Simulation to Synthetic Data</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Phisical-ai-book/docs/chapters/part2/chapter6"><span title="Chapter 6: Vision Systems and Perception" class="linkLabel_WmDU">Chapter 6: Vision Systems and Perception</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Phisical-ai-book/docs/chapters/part2/chapter7"><span title="Chapter 7: Vision-Language-Action (VLA) Models" class="linkLabel_WmDU">Chapter 7: Vision-Language-Action (VLA) Models</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Phisical-ai-book/docs/chapters/part2/chapter8"><span title="Chapter 8: Conversational Robotics" class="linkLabel_WmDU">Chapter 8: Conversational Robotics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Phisical-ai-book/docs/chapters/part3/chapter10"><span title="part3" class="categoryLinkLabel_W154">part3</span></a></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Phisical-ai-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">chapters</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">part2</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 7: Vision-Language-Action (VLA) Models</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 7: Vision-Language-Action (VLA) Models</h1></header>
<p>Our robot can now see. But sight without understanding is just data. To build a truly intelligent agent, that sight must be connected to language and, most importantly, to action. This chapter introduces a concept from the absolute cutting edge of AI research: Vision-Language-Action (VLA) models.</p>
<p>A VLA is a single AI model that can take both an image (vision) and a text command (language) as input, and produce a sequence of actions as output. It&#x27;s a model that embodies reasoning.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-a-vla-from-perception-to-understanding">What is a VLA? From Perception to Understanding<a href="#what-is-a-vla-from-perception-to-understanding" class="hash-link" aria-label="Direct link to What is a VLA? From Perception to Understanding" title="Direct link to What is a VLA? From Perception to Understanding" translate="no">â€‹</a></h2>
<p>Consider the command: &quot;bring me the red fruit from the bowl.&quot;</p>
<p>A simple perception model (like the one we built in Chapter 6) can tell you &quot;I see an apple, a banana, and a bowl.&quot; It identifies objects.</p>
<p>A VLA, on the other hand, can understand the <em>relationships</em> and the <em>goal</em> embedded in the command. It can reason:</p>
<ol>
<li class="">&quot;The user wants a &#x27;red fruit&#x27;. An apple is a fruit and it is red.&quot;</li>
<li class="">&quot;The apple is &#x27;from the bowl&#x27;.&quot; I see the apple is inside the bowl.</li>
<li class="">&quot;The goal is to &#x27;bring&#x27; it.&quot; This implies a sequence of actions: <code>move_to(bowl)</code>, <code>grasp(apple)</code>, <code>move_to(user)</code>.</li>
</ol>
<p>This is the leap from perception to <strong>embodied reasoning</strong>. VLAs are a cornerstone of modern Physical AI research, with major labs releasing models like Google&#x27;s PaLM-E and DeepMind&#x27;s Flamingo.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="architectural-overview">Architectural Overview<a href="#architectural-overview" class="hash-link" aria-label="Direct link to Architectural Overview" title="Direct link to Architectural Overview" translate="no">â€‹</a></h2>
<p>You do not need to build a VLA from scratch, but you should understand how they work conceptually.</p>
<p>A VLA typically has three main components:</p>
<ol>
<li class=""><strong>Vision Encoder</strong>: A pre-trained vision model (like the one from Chapter 6) that takes an image and converts it into a set of numerical features, or <strong>embeddings</strong>.</li>
<li class=""><strong>Language Encoder</strong>: A Large Language Model (LLM) that takes a text command and converts it into embeddings.</li>
<li class=""><strong>Action Decoder</strong>: This is the key component. It&#x27;s a neural network that takes the combined vision and language embeddings and outputs a plan, often formatted as a sequence of simple actions (e.g., <code>[MOVE, GRASP, LIFT]</code>).</li>
</ol>
<p><em>(Diagram: A high-level diagram showing an image and text going into an &quot;Encoder&quot; block, which feeds into an &quot;Action Decoder&quot; block, which outputs a sequence of actions.)</em></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="integrating-a-vla-into-ros-2">Integrating a VLA into ROS 2<a href="#integrating-a-vla-into-ros-2" class="hash-link" aria-label="Direct link to Integrating a VLA into ROS 2" title="Direct link to Integrating a VLA into ROS 2" translate="no">â€‹</a></h2>
<p>Our goal is practical: to use an existing, open-source VLA within our ROS 2 system. We will create a ROS 2 &quot;Action Server&quot; that takes a string command, orchestrates the inputs for the VLA, and returns the resulting plan.</p>
<p>Here&#x27;s the workflow for our <code>vla_action_server</code> node:</p>
<ol>
<li class="">The node receives a goal, which contains a high-level command like <code>&quot;get me the red cube&quot;</code>.</li>
<li class="">It captures the current image from the robot&#x27;s camera topic (<code>/camera/image_raw</code>).</li>
<li class="">It packages the image and the text command into the format expected by the VLA model.</li>
<li class="">It calls the VLA model&#x27;s <code>predict()</code> function.</li>
<li class="">The VLA returns a sequence of actions, for example: <code>[&#x27;MOVE_ARM_TO(0.5, 0.3, 0.2)&#x27;, &#x27;CLOSE_GRIPPER&#x27;, &#x27;MOVE_ARM_TO(0.2, 0.5, 0.4)&#x27;]</code>.</li>
<li class="">Our node publishes this action sequence to another topic (e.g., <code>/robot/action_plan</code>) or returns it as the result of the ROS 2 Action.</li>
</ol>
<p>Here&#x27;s an illustrative code snippet for the ROS 2 node:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Illustrative example of a VLA integration node</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ActionServer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sensor_msgs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">msg </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> my_robot_interfaces</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ExecuteVLA</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Assume &#x27;VlaModel&#x27; is a class that wraps an open-source VLA</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">vla_model </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> VlaModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">VlaActionServer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Node</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;vla_action_server&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">vla </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> VlaModel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;path/to/vla/weights&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">latest_image </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">subscription </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create_subscription</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Image</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;/camera/image_raw&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">image_callback</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">_action_server </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ActionServer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ExecuteVLA</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;execute_vla&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">execute_callback</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;VLA Action Server has started.&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">image_callback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> msg</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">latest_image </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> msg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">execute_callback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> goal_handle</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;Executing goal...&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        command </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> goal_handle</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">request</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">command</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">latest_image </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            goal_handle</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">abort</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> ExecuteVLA</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Result</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">plan</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;Error: No image available&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># This is where we call the VLA</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        action_plan </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">vla</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">command</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">latest_image</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal_handle</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">succeed</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ExecuteVLA</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Result</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">plan </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> action_plan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> result</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... main function to spin the node ...</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-note-on-fine-tuning">A Note on Fine-Tuning<a href="#a-note-on-fine-tuning" class="hash-link" aria-label="Direct link to A Note on Fine-Tuning" title="Direct link to A Note on Fine-Tuning" translate="no">â€‹</a></h3>
<p>While we are using a pre-trained model, it&#x27;s possible to &quot;fine-tune&quot; a VLA on your own data. By using the synthetic data pipeline from Chapter 5, you could generate thousands of examples of your robot performing specific tasks, and use that data to make the VLA even better at controlling your specific robot in its specific environment.</p>
<p>With this chapter, we have built the reasoning core of our robot. It can now connect what it sees with what it&#x27;s told to do. The final piece of the intelligence puzzle is to enable it to have a natural, back-and-forth conversation with a user. We will tackle this in the next chapter.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/HassanRaza477/Phisical-ai-book.git/docs/chapters/part2/chapter7.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Phisical-ai-book/docs/chapters/part2/chapter6"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 6: Vision Systems and Perception</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Phisical-ai-book/docs/chapters/part2/chapter8"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 8: Conversational Robotics</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-a-vla-from-perception-to-understanding" class="table-of-contents__link toc-highlight">What is a VLA? From Perception to Understanding</a></li><li><a href="#architectural-overview" class="table-of-contents__link toc-highlight">Architectural Overview</a></li><li><a href="#integrating-a-vla-into-ros-2" class="table-of-contents__link toc-highlight">Integrating a VLA into ROS 2</a><ul><li><a href="#a-note-on-fine-tuning" class="table-of-contents__link toc-highlight">A Note on Fine-Tuning</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Textbook</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/intro">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/physical-ai/overview">Physical AI</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/humanoids/overview">Humanoid Robotics</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/simulation/overview">Simulation</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/advanced-ai/vla-models">VLA Models</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/capstone/autonomous-humanoid">Capstone</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Tools</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/tools/ros2">ROS 2</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/tools/gazebo-unity">Gazebo + Unity</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/tools/isaac-sim">NVIDIA Isaac</a></li><li class="footer__item"><a href="https://github.com/panaversity/physical-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Code Examples<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/tools/api">API Reference</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ai-native.panaversity.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Panaversity Portal<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discord.gg/physical-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord Community<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/panaversity_ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">X (Twitter)<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/panaversity/physical-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://youtube.com/@panaversity" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Hackathon</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ai-native.panaversity.org/hackathon" target="_blank" rel="noopener noreferrer" class="footer__link-item">Hackathon Details<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://ai-native.panaversity.org/register" target="_blank" rel="noopener noreferrer" class="footer__link-item">Register Team<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/hackathon/guidelines">Project Guidelines</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/hackathon/judging">Judging Criteria</a></li><li class="footer__item"><a class="footer__link-item" href="/Phisical-ai-book/docs/hackathon/mentors">Mentors</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a class="footerLogoLink_BH7S" href="/Phisical-ai-book/"><img src="/Phisical-ai-book/img/logo-footer.svg" alt="Physical AI &amp; Humanoid Robotics Logo" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE" width="160" height="40"><img src="/Phisical-ai-book/img/logo-footer.svg" alt="Physical AI &amp; Humanoid Robotics Logo" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU" width="160" height="40"></a></div><div class="footer__copyright">Â© 2025 Physical AI & Humanoid Robotics â€” Panaversity. Built with Docusaurus and AI Agents.</div></div></div></footer></div>
</body>
</html>